{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\"> Week 8 - Ensemble Methods</p>\n",
    "##    <p style=\"text-align: center;\">Seve Martinez </p>\n",
    "##    <p style=\"text-align: center;\">Grand Canyon University </p>\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align: center;\"> Abstract</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble methods can be a great way to improve the predictive ability of a data science model. There are several methods including bagging (bootstrap aggregating), bagging, and others. In this paper, a custom implementation is proposed using three fusion methods: Weighted Majority Voting, Behavior Knowledge Space, and Naive Bayes Combination. The data set PAMAP is used from the UCI machine learning repository. \n",
    "\n",
    "Keywords: ensemble methods, ANN, BDT, SVM, weighted majority voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 8 – Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Ensemble methods seek to take a series of weak learners and combine their results to build a stronger and more robust model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    <p style=\"text-align: center;\"> Methods </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 8 – Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The data set comes from the PAMAP Physical Activity Monitoring study from UCI Machine learning repository. The data contains 54 columns of various data points from three accelerometers, worn in different locations on the body. Nine subjects were measured while doing various activities of differing exertion levels. Some activities include walking, lying down, sitting, ironing, cycling, and others. A sampling rate of 100Hz was used to capture data on a 3D axis of ± 16g. While three locations were used, only the wrist location was used for the study (Chowdhary et al, 2017). \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Additional features were then calculated from the three columns of wrist data which include mean, median, standard deviation, variance, skewness, and kurtosis. Chowdhary et al used a 10-second sliding window on the timestamp value, but this proved to be programatically challenging so, given the time, a random sampling of ten records was chosen for each row set of the additional features. This will produce somewhat inaccurate data because dissimilar time stamped values could be for different activities, which will skew the data. However, for the purposes of this paper, this was an acceptable compromise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os # for the file merging\n",
    "from sklearn.impute import SimpleImputer # To handle the null values\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import VotingClassifier # Weighted Voting ('soft')\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "from sklearn.svm import SVC # Support vector machine\n",
    "from sklearn.neural_network import MLPClassifier # ANN\n",
    "from sklearn.tree import DecisionTreeClassifier # Binary decision tree\n",
    "from sklearn.naive_bayes import MultinomialNB # For the Behavior Knowledge Space\n",
    "from sklearn.naive_bayes import GaussianNB # Naive Bayes\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are nine files, one per subject. So all will be combined in order to simplify the process.\n",
    "\n",
    "path = '../data/PAMAP2_Dataset/Protocol'\n",
    "\n",
    "file_list = os.listdir(path)\n",
    "for filename in sorted(file_list):\n",
    "    out_filename = 'pamap.txt'\n",
    "    with open(out_filename, 'a') as outfile:\n",
    "        with open(path + '/' + filename, 'r') as infile:\n",
    "            outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the combined subject dataset into a dataframe\n",
    "# The study only used the wrist data, so the rest is dropped\n",
    "\n",
    "cols = ['timestamp', 'activityID', 'heartrate', 'w1', 'w2', 'w3', 'w4', 'w5', 'w6'\n",
    "        ,'w7', 'w8', 'w9', 'w10', 'w11', 'w12', 'w13', 'w14', 'w15', 'w16', 'w17']\n",
    "\n",
    "df = pd.read_csv('pamap.txt', ' ', header=None)\n",
    "\n",
    "df.drop(df.iloc[:, 20:], axis = 1, inplace=True)\n",
    "df.columns=cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2872533, 20)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     929661\n",
       "4     238761\n",
       "17    238690\n",
       "1     192523\n",
       "3     189931\n",
       "7     188107\n",
       "2     185188\n",
       "16    175353\n",
       "6     164600\n",
       "12    117216\n",
       "13    104944\n",
       "5      98199\n",
       "24     49360\n",
       "Name: activityID, dtype: int64"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['activityID'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'activityID', 'w2', 'w3', 'w4'], dtype='object')"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Per the dataset instructions, an activityID of 0 should be removed\n",
    "# The study did not explicitly state whether or not they removed it,\n",
    "# but it would be prudent to do so.\n",
    "# Only the data from the accelerometer is used so heartrate will also be dropped.\n",
    "# In addition, only values w2-4 are for the +/- 16g accelerometer\n",
    "# Which is the one used in the study. The other columns will be dropped.\n",
    "\n",
    "df.drop(df[df['activityID'] == 0].index, inplace=True)\n",
    "#df.drop('heartrate', inplace=True, axis=1)\n",
    "\n",
    "keeps = ['timestamp', 'activityID', 'w2', 'w3', 'w4']\n",
    "df = df[keeps]\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>activityID</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19193</th>\n",
       "      <td>200.31</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19194</th>\n",
       "      <td>200.32</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19195</th>\n",
       "      <td>200.33</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34152</th>\n",
       "      <td>349.90</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45999</th>\n",
       "      <td>468.37</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843922</th>\n",
       "      <td>3884.86</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843923</th>\n",
       "      <td>3884.87</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843950</th>\n",
       "      <td>3885.14</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871906</th>\n",
       "      <td>93.97</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871907</th>\n",
       "      <td>93.98</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11124 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         timestamp  activityID  w2  w3  w4\n",
       "19193       200.31           1 NaN NaN NaN\n",
       "19194       200.32           1 NaN NaN NaN\n",
       "19195       200.33           1 NaN NaN NaN\n",
       "34152       349.90           2 NaN NaN NaN\n",
       "45999       468.37           2 NaN NaN NaN\n",
       "...            ...         ...  ..  ..  ..\n",
       "2843922    3884.86          24 NaN NaN NaN\n",
       "2843923    3884.87          24 NaN NaN NaN\n",
       "2843950    3885.14          24 NaN NaN NaN\n",
       "2871906      93.97          24 NaN NaN NaN\n",
       "2871907      93.98          24 NaN NaN NaN\n",
       "\n",
       "[11124 rows x 5 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So we have quite a few null values that will have to be handled.\n",
    "# There are a consistent number of nulls that comprise only 0.5% of the entire dataset\n",
    "# The easiest thing would be to drop them, but in the spirit of the study, they will\n",
    "# be imputed.\n",
    "\n",
    "# The authors used linear interpolation to determine the values, but for simplicity,\n",
    "# mean will be used here.\n",
    "df[df['w2'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp     False\n",
       "activityID    False\n",
       "w2            False\n",
       "w3            False\n",
       "w4            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The authors used linear interpolation to determine the values, but for simplicity,\n",
    "# mean will be used here.\n",
    "# Use the simpleimputer class from sklearn and leverage 'mean' as the fill value\n",
    "fill_NaN = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputed_df = pd.DataFrame(fill_NaN.fit_transform(df))\n",
    "\n",
    "# Rebuild the dataframe\n",
    "imputed_df.columns = df.columns\n",
    "imputed_df.index = df.index\n",
    "\n",
    "# Verify it worked\n",
    "imputed_df.head().isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1942872, 5)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the first ten seconds and the last ten seconds\n",
    "# to ensure steady state data\n",
    "\n",
    "indexNames = imputed_df[(imputed_df['timestamp'] <= imputed_df['timestamp'].min()+10) | (imputed_df['timestamp'] >= imputed_df['timestamp'].max()-10)].index\n",
    "\n",
    "# Remove the values\n",
    "imputed_df.drop(indexNames , inplace=True)\n",
    "\n",
    "\n",
    "# Reset the index after doing all this\n",
    "imputed_df.reset_index(inplace=True)\n",
    "imputed_df.drop('index', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>activityID</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.34587</td>\n",
       "      <td>9.57245</td>\n",
       "      <td>2.83571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.76211</td>\n",
       "      <td>10.63590</td>\n",
       "      <td>2.59496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.45116</td>\n",
       "      <td>11.09340</td>\n",
       "      <td>2.23671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.42381</td>\n",
       "      <td>11.88590</td>\n",
       "      <td>1.77260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.31581</td>\n",
       "      <td>12.45170</td>\n",
       "      <td>1.50289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940510</th>\n",
       "      <td>95.06</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.99466</td>\n",
       "      <td>6.01881</td>\n",
       "      <td>5.59830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940511</th>\n",
       "      <td>95.07</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.02764</td>\n",
       "      <td>5.90369</td>\n",
       "      <td>5.48372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940512</th>\n",
       "      <td>95.08</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.06409</td>\n",
       "      <td>5.71370</td>\n",
       "      <td>5.48491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940513</th>\n",
       "      <td>95.09</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.13914</td>\n",
       "      <td>5.63724</td>\n",
       "      <td>5.48629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940514</th>\n",
       "      <td>95.10</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.00812</td>\n",
       "      <td>5.40645</td>\n",
       "      <td>5.02326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1940515 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         timestamp  activityID       w2        w3       w4\n",
       "0            41.21         1.0 -1.34587   9.57245  2.83571\n",
       "1            41.22         1.0 -1.76211  10.63590  2.59496\n",
       "2            41.23         1.0 -2.45116  11.09340  2.23671\n",
       "3            41.24         1.0 -2.42381  11.88590  1.77260\n",
       "4            41.25         1.0 -2.31581  12.45170  1.50289\n",
       "...            ...         ...      ...       ...      ...\n",
       "1940510      95.06        24.0  4.99466   6.01881  5.59830\n",
       "1940511      95.07        24.0  5.02764   5.90369  5.48372\n",
       "1940512      95.08        24.0  5.06409   5.71370  5.48491\n",
       "1940513      95.09        24.0  5.13914   5.63724  5.48629\n",
       "1940514      95.10        24.0  5.00812   5.40645  5.02326\n",
       "\n",
       "[1940515 rows x 5 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df = imputed_df.sample(n=200000)\n",
    "imputed_df.reset_index(inplace=True)\n",
    "imputed_df.drop('index', inplace=True, axis=1)\n",
    "t = imputed_df.sample(n=10)\n",
    "\n",
    "new_serie = t.agg(['sum'\n",
    "                   ,'mean'\n",
    "                   ,'var'\n",
    "                   ,'std'\n",
    "                   ,'skew'\n",
    "                   ,'kurt'\n",
    "                   ,'median'\n",
    "                   ,'min'\n",
    "                   ,'max']).unstack()\n",
    "\n",
    "new_df = pd.concat([imputed_df, new_serie.set_axis([f'{x}_{y}'\n",
    "                                for x, y in new_serie.index])\n",
    "                                  .to_frame().T], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop back through and update the dataset\n",
    "for i in range(0, len(imputed_df)):\n",
    "    t = imputed_df.sample(n=10)\n",
    "    new_serie = t.agg(['sum'\n",
    "                       ,'mean'\n",
    "                       ,'var'\n",
    "                       ,'std'\n",
    "                       ,'skew'\n",
    "                       ,'kurt'\n",
    "                       ,'median'\n",
    "                       ,'min'\n",
    "                       ,'max']).unstack()\n",
    "    \n",
    "    \n",
    "    #if new_df already exist:\n",
    "    new_df.loc[i, :] = new_serie.set_axis([f'{x}_{y}' for x, y in new_serie.index])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some reason it clobbers the original rows, so drop them and rejoin to the old one\n",
    "new_df.drop(['timestamp', 'activityID', 'w2', 'w3', 'w4'], inplace=True, axis=1)\n",
    "final_df = imputed_df.join(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>activityID</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "      <th>timestamp_sum</th>\n",
       "      <th>timestamp_mean</th>\n",
       "      <th>timestamp_var</th>\n",
       "      <th>timestamp_std</th>\n",
       "      <th>timestamp_skew</th>\n",
       "      <th>...</th>\n",
       "      <th>w3_skew</th>\n",
       "      <th>w3_kurt</th>\n",
       "      <th>w3_median</th>\n",
       "      <th>w4_sum</th>\n",
       "      <th>w4_mean</th>\n",
       "      <th>w4_var</th>\n",
       "      <th>w4_std</th>\n",
       "      <th>w4_skew</th>\n",
       "      <th>w4_kurt</th>\n",
       "      <th>w4_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2721.29</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-6.71878</td>\n",
       "      <td>14.914300</td>\n",
       "      <td>1.467120</td>\n",
       "      <td>16541.81</td>\n",
       "      <td>1654.181</td>\n",
       "      <td>9.264337e+05</td>\n",
       "      <td>962.514282</td>\n",
       "      <td>-0.393664</td>\n",
       "      <td>...</td>\n",
       "      <td>1.896776</td>\n",
       "      <td>5.104444</td>\n",
       "      <td>4.041105</td>\n",
       "      <td>48.114755</td>\n",
       "      <td>4.811476</td>\n",
       "      <td>9.590619</td>\n",
       "      <td>3.096873</td>\n",
       "      <td>0.257536</td>\n",
       "      <td>-1.661255</td>\n",
       "      <td>3.986475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1840.01</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-6.55117</td>\n",
       "      <td>3.081560</td>\n",
       "      <td>2.202320</td>\n",
       "      <td>15757.92</td>\n",
       "      <td>1575.792</td>\n",
       "      <td>1.056256e+06</td>\n",
       "      <td>1027.743333</td>\n",
       "      <td>0.447349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417718</td>\n",
       "      <td>-0.043661</td>\n",
       "      <td>3.638440</td>\n",
       "      <td>24.615158</td>\n",
       "      <td>2.461516</td>\n",
       "      <td>16.156464</td>\n",
       "      <td>4.019510</td>\n",
       "      <td>0.570342</td>\n",
       "      <td>-0.759230</td>\n",
       "      <td>1.827280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>900.84</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-6.76244</td>\n",
       "      <td>2.671800</td>\n",
       "      <td>7.088440</td>\n",
       "      <td>12621.53</td>\n",
       "      <td>1262.153</td>\n",
       "      <td>7.861352e+05</td>\n",
       "      <td>886.642656</td>\n",
       "      <td>0.309393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568219</td>\n",
       "      <td>1.688135</td>\n",
       "      <td>4.994155</td>\n",
       "      <td>46.046140</td>\n",
       "      <td>4.604614</td>\n",
       "      <td>6.160259</td>\n",
       "      <td>2.481987</td>\n",
       "      <td>0.259665</td>\n",
       "      <td>-1.374382</td>\n",
       "      <td>4.409425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.45717</td>\n",
       "      <td>-1.454100</td>\n",
       "      <td>4.597730</td>\n",
       "      <td>22653.49</td>\n",
       "      <td>2265.349</td>\n",
       "      <td>1.361728e+06</td>\n",
       "      <td>1166.930937</td>\n",
       "      <td>-1.127839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082441</td>\n",
       "      <td>0.119479</td>\n",
       "      <td>4.502360</td>\n",
       "      <td>20.977467</td>\n",
       "      <td>2.097747</td>\n",
       "      <td>13.730057</td>\n",
       "      <td>3.705409</td>\n",
       "      <td>-0.713149</td>\n",
       "      <td>0.593306</td>\n",
       "      <td>2.404555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000.69</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-13.20160</td>\n",
       "      <td>2.120250</td>\n",
       "      <td>3.414520</td>\n",
       "      <td>20768.58</td>\n",
       "      <td>2076.858</td>\n",
       "      <td>1.003401e+06</td>\n",
       "      <td>1001.699270</td>\n",
       "      <td>-0.837843</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.441202</td>\n",
       "      <td>0.091522</td>\n",
       "      <td>3.690055</td>\n",
       "      <td>37.447436</td>\n",
       "      <td>3.744744</td>\n",
       "      <td>8.568038</td>\n",
       "      <td>2.927121</td>\n",
       "      <td>0.204204</td>\n",
       "      <td>-0.517594</td>\n",
       "      <td>3.506080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>3010.11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-7.48967</td>\n",
       "      <td>1.103940</td>\n",
       "      <td>9.315100</td>\n",
       "      <td>9234.84</td>\n",
       "      <td>923.484</td>\n",
       "      <td>1.020397e+06</td>\n",
       "      <td>1010.147091</td>\n",
       "      <td>2.354490</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.911651</td>\n",
       "      <td>8.854461</td>\n",
       "      <td>5.893685</td>\n",
       "      <td>48.164091</td>\n",
       "      <td>4.816409</td>\n",
       "      <td>10.268572</td>\n",
       "      <td>3.204461</td>\n",
       "      <td>-1.138176</td>\n",
       "      <td>-0.169199</td>\n",
       "      <td>6.001230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>3030.91</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-10.28910</td>\n",
       "      <td>-0.221495</td>\n",
       "      <td>2.927220</td>\n",
       "      <td>18681.62</td>\n",
       "      <td>1868.162</td>\n",
       "      <td>1.802452e+06</td>\n",
       "      <td>1342.554208</td>\n",
       "      <td>0.385985</td>\n",
       "      <td>...</td>\n",
       "      <td>1.572348</td>\n",
       "      <td>4.206410</td>\n",
       "      <td>2.572815</td>\n",
       "      <td>54.723290</td>\n",
       "      <td>5.472329</td>\n",
       "      <td>8.105623</td>\n",
       "      <td>2.847038</td>\n",
       "      <td>0.386852</td>\n",
       "      <td>-0.504066</td>\n",
       "      <td>5.113615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>302.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.08045</td>\n",
       "      <td>-0.256253</td>\n",
       "      <td>8.276380</td>\n",
       "      <td>13991.12</td>\n",
       "      <td>1399.112</td>\n",
       "      <td>1.188831e+06</td>\n",
       "      <td>1090.335146</td>\n",
       "      <td>0.680787</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.739108</td>\n",
       "      <td>8.179653</td>\n",
       "      <td>4.010380</td>\n",
       "      <td>36.827149</td>\n",
       "      <td>3.682715</td>\n",
       "      <td>9.507849</td>\n",
       "      <td>3.083480</td>\n",
       "      <td>0.309082</td>\n",
       "      <td>-1.684113</td>\n",
       "      <td>2.860450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>2385.57</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.62356</td>\n",
       "      <td>7.983600</td>\n",
       "      <td>-0.378975</td>\n",
       "      <td>20974.66</td>\n",
       "      <td>2097.466</td>\n",
       "      <td>9.796520e+05</td>\n",
       "      <td>989.773724</td>\n",
       "      <td>-0.694516</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016564</td>\n",
       "      <td>-1.363516</td>\n",
       "      <td>-1.474430</td>\n",
       "      <td>34.968217</td>\n",
       "      <td>3.496822</td>\n",
       "      <td>5.330679</td>\n",
       "      <td>2.308826</td>\n",
       "      <td>0.630594</td>\n",
       "      <td>0.062462</td>\n",
       "      <td>3.266260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>2914.80</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-12.45550</td>\n",
       "      <td>5.443550</td>\n",
       "      <td>-1.896780</td>\n",
       "      <td>19454.94</td>\n",
       "      <td>1945.494</td>\n",
       "      <td>7.896505e+05</td>\n",
       "      <td>888.622826</td>\n",
       "      <td>-0.028955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871773</td>\n",
       "      <td>0.776339</td>\n",
       "      <td>2.336750</td>\n",
       "      <td>54.638828</td>\n",
       "      <td>5.463883</td>\n",
       "      <td>11.685051</td>\n",
       "      <td>3.418340</td>\n",
       "      <td>0.108031</td>\n",
       "      <td>-1.759184</td>\n",
       "      <td>4.558575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        timestamp  activityID        w2         w3        w4  timestamp_sum  \\\n",
       "0         2721.29         7.0  -6.71878  14.914300  1.467120       16541.81   \n",
       "1         1840.01        13.0  -6.55117   3.081560  2.202320       15757.92   \n",
       "2          900.84        17.0  -6.76244   2.671800  7.088440       12621.53   \n",
       "3          194.16         1.0   8.45717  -1.454100  4.597730       22653.49   \n",
       "4         3000.69         4.0 -13.20160   2.120250  3.414520       20768.58   \n",
       "...           ...         ...       ...        ...       ...            ...   \n",
       "199995    3010.11         6.0  -7.48967   1.103940  9.315100        9234.84   \n",
       "199996    3030.91         6.0 -10.28910  -0.221495  2.927220       18681.62   \n",
       "199997     302.91         1.0   5.08045  -0.256253  8.276380       13991.12   \n",
       "199998    2385.57         4.0  -5.62356   7.983600 -0.378975       20974.66   \n",
       "199999    2914.80         4.0 -12.45550   5.443550 -1.896780       19454.94   \n",
       "\n",
       "        timestamp_mean  timestamp_var  timestamp_std  timestamp_skew  ...  \\\n",
       "0             1654.181   9.264337e+05     962.514282       -0.393664  ...   \n",
       "1             1575.792   1.056256e+06    1027.743333        0.447349  ...   \n",
       "2             1262.153   7.861352e+05     886.642656        0.309393  ...   \n",
       "3             2265.349   1.361728e+06    1166.930937       -1.127839  ...   \n",
       "4             2076.858   1.003401e+06    1001.699270       -0.837843  ...   \n",
       "...                ...            ...            ...             ...  ...   \n",
       "199995         923.484   1.020397e+06    1010.147091        2.354490  ...   \n",
       "199996        1868.162   1.802452e+06    1342.554208        0.385985  ...   \n",
       "199997        1399.112   1.188831e+06    1090.335146        0.680787  ...   \n",
       "199998        2097.466   9.796520e+05     989.773724       -0.694516  ...   \n",
       "199999        1945.494   7.896505e+05     888.622826       -0.028955  ...   \n",
       "\n",
       "         w3_skew   w3_kurt  w3_median     w4_sum   w4_mean     w4_var  \\\n",
       "0       1.896776  5.104444   4.041105  48.114755  4.811476   9.590619   \n",
       "1       0.417718 -0.043661   3.638440  24.615158  2.461516  16.156464   \n",
       "2       0.568219  1.688135   4.994155  46.046140  4.604614   6.160259   \n",
       "3       0.082441  0.119479   4.502360  20.977467  2.097747  13.730057   \n",
       "4      -0.441202  0.091522   3.690055  37.447436  3.744744   8.568038   \n",
       "...          ...       ...        ...        ...       ...        ...   \n",
       "199995 -2.911651  8.854461   5.893685  48.164091  4.816409  10.268572   \n",
       "199996  1.572348  4.206410   2.572815  54.723290  5.472329   8.105623   \n",
       "199997 -2.739108  8.179653   4.010380  36.827149  3.682715   9.507849   \n",
       "199998 -0.016564 -1.363516  -1.474430  34.968217  3.496822   5.330679   \n",
       "199999  0.871773  0.776339   2.336750  54.638828  5.463883  11.685051   \n",
       "\n",
       "          w4_std   w4_skew   w4_kurt  w4_median  \n",
       "0       3.096873  0.257536 -1.661255   3.986475  \n",
       "1       4.019510  0.570342 -0.759230   1.827280  \n",
       "2       2.481987  0.259665 -1.374382   4.409425  \n",
       "3       3.705409 -0.713149  0.593306   2.404555  \n",
       "4       2.927121  0.204204 -0.517594   3.506080  \n",
       "...          ...       ...       ...        ...  \n",
       "199995  3.204461 -1.138176 -0.169199   6.001230  \n",
       "199996  2.847038  0.386852 -0.504066   5.113615  \n",
       "199997  3.083480  0.309082 -1.684113   2.860450  \n",
       "199998  2.308826  0.630594  0.062462   3.266260  \n",
       "199999  3.418340  0.108031 -1.759184   4.558575  \n",
       "\n",
       "[200000 rows x 40 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = StandardScaler()\n",
    "\n",
    "X = final_df.drop('activityID', axis=1)\n",
    "X = se.fit_transform(X)\n",
    "y = final_df['activityID']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Models\n",
    "### Binary Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 was the max depth the authors used.\n",
    "dt_clf = DecisionTreeClassifier(random_state=69, max_depth=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors used 7 neighbors\n",
    "k_clf = KNeighborsClassifier(n_neighbors=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a 'one-vs-rest' type SVM\n",
    "svm_clf = SVC(decision_function_shape='ovr', probability=True, kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 neurons in the hidden layer\n",
    "# linear activation 'ReLu'\n",
    "# learning rate = 0.001\n",
    "# 250 epochs\n",
    "\n",
    "ann_clf = MLPClassifier(hidden_layer_sizes=(50,), max_iter=250, random_state=69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('BDT',\n",
       "                              DecisionTreeClassifier(max_depth=20,\n",
       "                                                     random_state=69)),\n",
       "                             ('knn', KNeighborsClassifier(n_neighbors=7)),\n",
       "                             ('svm', SVC(kernel='linear', probability=True)),\n",
       "                             ('ann',\n",
       "                              MLPClassifier(hidden_layer_sizes=(50,),\n",
       "                                            max_iter=250, random_state=69))],\n",
       "                 n_jobs=15, voting='soft')"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unleash the kraken!\n",
    "wmv_clf = VotingClassifier(estimators=[\n",
    "        ('BDT', dt_clf)\n",
    "    ,('knn', k_clf)\n",
    "    ,('svm', svm_clf)\n",
    "    ,('ann', ann_clf)], voting='soft', n_jobs=-1)\n",
    "\n",
    "\n",
    "wmv_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3857,   25,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           4],\n",
       "       [  15, 3814,   69,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [   0,   85, 3712,    0,    0,    0,    0,    0,    0,    0,   88,\n",
       "           0],\n",
       "       [   0,    0,    0, 4995,    2,   49,   49,    2,    4,    0,    0,\n",
       "           0],\n",
       "       [   0,    0,    0,   10, 1765,   83,  111,    0,    0,    0,    0,\n",
       "          36],\n",
       "       [   0,    0,    0,   89,   42, 3147,   65,    0,    0,    0,    0,\n",
       "           8],\n",
       "       [   0,    0,    0,   59,   88,   48, 3541,    0,    7,    0,    0,\n",
       "           4],\n",
       "       [   0,    0,    0,  137,    0,    0,    4, 1921,  330,  107,    0,\n",
       "           0],\n",
       "       [   0,    0,    0,   47,    0,    0,   25,  522, 1654,    0,    0,\n",
       "           0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,   74,    0, 3364,   99,\n",
       "           0],\n",
       "       [   0,    1,   84,    0,    0,    0,    0,    0,    0,   73, 4761,\n",
       "           0],\n",
       "       [  35,    0,    0,    0,   83,   56,   13,    0,    0,    0,    0,\n",
       "         737]])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = wmv_clf.predict(X_test)\n",
    "\n",
    "# Build the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9317"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmv_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0     5101\n",
       "17.0    4919\n",
       "2.0     3898\n",
       "1.0     3886\n",
       "3.0     3885\n",
       "7.0     3747\n",
       "16.0    3537\n",
       "6.0     3351\n",
       "12.0    2499\n",
       "13.0    2248\n",
       "5.0     2005\n",
       "24.0     924\n",
       "Name: activityID, dtype: int64"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ann:  {0.008025}\n",
      "BDT:  {0.0034}\n",
      "SVM:  {0.02585}\n",
      "knn:  {0.040525}\n"
     ]
    }
   ],
   "source": [
    "# See how weak weak classifier did prior to the ensemble\n",
    "print('Ann: ', {wmv_clf.named_estimators_['ann'].score(X_test, y_test)})\n",
    "print('BDT: ', {wmv_clf.named_estimators_['BDT'].score(X_test, y_test)})\n",
    "print('SVM: ', {wmv_clf.named_estimators_['svm'].score(X_test, y_test)})\n",
    "print('knn: ', {wmv_clf.named_estimators_['knn'].score(X_test, y_test)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BKS Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wasn't sure how to do this one, so used a multinomialNB to combine the classifiers' outputs.\n",
    "\n",
    "\n",
    "bks_clf = MultinomialNB().fit(nb_data, y_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
